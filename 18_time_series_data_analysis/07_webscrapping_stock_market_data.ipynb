{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:yellow;font-weight:bold;text-decoration:underline; font-size:50px\">Stock market data scrapping</span> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why stock market data scrapping is important?\n",
    "Stock market data scraping is important because it allows traders and investors to gather large amounts of data from various sources, analyze it, and make informed decisions based on the insights gained. This can include tracking stock prices, analyzing market trends, and monitoring news and social media sentiment. Additionally, stock market data scraping can help traders and investors identify potential risks and opportunities, and make more informed decisions about when to buy or sell stocks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several libraries that can be used to scrape stock market data in Python. Some popular ones include:\n",
    "\n",
    "1. BeautifulSoup\n",
    "2. Scrapy\n",
    "3. Selenium\n",
    "4. Pandas\n",
    "5. Requests\n",
    "\n",
    "Each of these libraries has its own strengths and weaknesses, and the choice of which one to use will depend on the specific requirements of your project. For example, if you need to scrape data from dynamic websites that require user interaction, you may want to use Selenium. If you need to scrape data from multiple pages or websites, Scrapy may be a good choice. If you need to manipulate and analyze the data after scraping it, Pandas may be the way to go."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Code for Scraping Stock Prices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of how to use yfinance to get the stock price of Apple (AAPL):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200.85000610351562\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Define the ticker symbol\n",
    "tickerSymbol = 'AAPL'\n",
    "\n",
    "# Get data on this ticker\n",
    "tickerData = yf.Ticker(tickerSymbol)\n",
    "\n",
    "# Get the stock price history\n",
    "tickerDf = tickerData.history(period='1d', start='2024-06-01', end='2025-06-01')\n",
    "\n",
    "# Get the last closing price\n",
    "lastPrice = tickerDf['Close'].iloc[-1]\n",
    "\n",
    "# Print the last closing price\n",
    "print(lastPrice)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This code uses the yfinance library to get data on the AAPL ticker, including its stock price history. It then extracts the last closing price from the history and prints it to the console. Note that you can adjust the `start` and `end` dates to get the stock price history for a different time period."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:yellow;font-weight:bold;text-decoration:underline; font-size:50px\">Web Scrapping vs. web crawling</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Web scraping` and `web crawling` are two related but distinct techniques for gathering data from the web.\n",
    "\n",
    "`Web scraping` involves `extracting specific data from web pages`, typically using tools like `BeautifulSoup` or `Scrapy` in Python. \n",
    "- This data can be used for a variety of purposes, such as analyzing market trends, monitoring social media sentiment, or gathering product information for price comparison websites.\n",
    "\n",
    "`Web crawling`, on the other hand, involves systematically exploring the web to gather data, typically using automated bots or spiders. \n",
    "- This data can be used to create search engine indexes, monitor website changes, or gather data for academic research.\n",
    "\n",
    "In summary, `web scraping is focused on extracting specific data from web pages`, while `web crawling is focused on systematically exploring the web to gather data`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:orange;font-weight:bold;font-size:30px\">Challenges scrapping stockmarket data</span>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several common challenges when scraping stock market data, including:\n",
    "\n",
    "1. `Dynamic websites:` Many stock market websites use dynamic content that is generated by JavaScript, which can make it difficult to scrape the data using traditional web scraping techniques. In these cases, you may need to use a tool like Selenium to automate a web browser and interact with the website in order to scrape the data.\n",
    "\n",
    "2. `Anti-scraping measures:` Some websites may have anti-scraping measures in place to prevent automated scraping. These measures can include CAPTCHAs, IP blocking, or user agent detection. To avoid these measures, you may need to use techniques like rotating IP addresses or user agents, or using a proxy server.\n",
    "\n",
    "3. `Data formatting:` Stock market data can be presented in a variety of formats, including tables, charts, and graphs. Extracting the data from these formats can be challenging, and may require specialized tools or techniques.\n",
    "\n",
    "4. `Data quality:` Stock market data can be noisy and contain errors or outliers. It's important to carefully clean and validate the data before using it for analysis or decision-making.\n",
    "\n",
    "5. `Legal and ethical considerations:` Scraping stock market data can raise legal and ethical concerns, particularly if the data is used for insider trading or other illegal activities. It's important to ensure that your scraping activities are legal and ethical, and to obtain any necessary permissions or licenses before scraping data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:orange;font-weight:bold;font-size:30px\">Techniques to avoid anti-scraping measures when scraping stock market data?</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several techniques that can be used to avoid anti-scraping measures when scraping stock market data, including:\n",
    "\n",
    "1. Use a proxy server: A proxy server can be used to route your requests through a different IP address, which can help you avoid IP blocking. There are several free and paid proxy services available that you can use.\n",
    "\n",
    "2. Rotate user agents: Some websites may block requests from certain user agents, so rotating your user agent can help you avoid detection. You can use a library like `fake_useragent` in Python to generate random user agents for each request.\n",
    "\n",
    "3. Slow down your requests: Sending too many requests too quickly can trigger anti-scraping measures, so slowing down your requests can help you avoid detection. You can use a library like `time` in Python to add a delay between each request.\n",
    "\n",
    "4. Use CAPTCHA solving services: Some websites may require you to solve a CAPTCHA in order to access the data. There are several CAPTCHA solving services available that you can use to automate this process.\n",
    "\n",
    "5. Use headless browsers: Some websites may use JavaScript to generate content, which can make it difficult to scrape the data using traditional web scraping techniques. Using a headless browser like Selenium can help you automate the process of interacting with the website and scraping the data.\n",
    "\n",
    "It's important to note that while these techniques can help you avoid anti-scraping measures, they may not be foolproof and may still result in your requests being blocked or your IP address being banned. It's always a good idea to check the website's terms of service and to be respectful of their policies when scraping data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:orange;font-weight:bold;font-size:30px\">What are some common data formatting issues when scraping stock market data?</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several common data formatting issues when scraping stock market data, including:\n",
    "\n",
    "1. `Inconsistent data types:` Stock market data can be presented in a variety of formats, including text, numbers, and dates. It's important to ensure that the data is consistently formatted and that the data types are correct before using it for analysis.\n",
    "\n",
    "2. Missing data: Stock market data can be incomplete or missing, which can make it difficult to analyze. It's important to handle missing data appropriately, either by imputing missing values or by excluding them from the analysis.\n",
    "\n",
    "3. `Non-standard data formats:` Some stock market data may be presented in non-standard formats, such as PDFs or images. Extracting data from these formats can be challenging and may require specialized tools or techniques.\n",
    "\n",
    "4. `Data normalization:` Stock market data can be presented in different units or currencies, which can make it difficult to compare across different stocks or markets. It's important to normalize the data to a common unit or currency before using it for analysis.\n",
    "\n",
    "5. `Data cleaning:` Stock market data can be noisy and contain errors or outliers. It's important to carefully clean and validate the data before using it for analysis or decision-making.\n",
    "\n",
    "It's important to be aware of these formatting issues when scraping stock market data and to take steps to address them before using the data for analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's scrape some stock market data!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure! Here's an example code snippet that uses yfinance to download the stock data of Google (GOOGL) for the last year from today and stores it in a Pandas DataFrame:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Open        High         Low       Close  \\\n",
      "Date                                                                        \n",
      "2025-05-23 00:00:00-04:00  169.059998  169.960007  167.889999  168.470001   \n",
      "2025-05-27 00:00:00-04:00  170.160004  173.169998  170.000000  172.899994   \n",
      "2025-05-28 00:00:00-04:00  173.160004  175.270004  171.910004  172.360001   \n",
      "2025-05-29 00:00:00-04:00  174.000000  174.419998  170.630005  171.860001   \n",
      "2025-05-30 00:00:00-04:00  171.350006  172.210007  167.440002  171.740005   \n",
      "\n",
      "                             Volume  Dividends  Stock Splits  \n",
      "Date                                                          \n",
      "2025-05-23 00:00:00-04:00  35211400        0.0           0.0  \n",
      "2025-05-27 00:00:00-04:00  37995700        0.0           0.0  \n",
      "2025-05-28 00:00:00-04:00  34784000        0.0           0.0  \n",
      "2025-05-29 00:00:00-04:00  29373800        0.0           0.0  \n",
      "2025-05-30 00:00:00-04:00  52605000        0.0           0.0  \n",
      "                                 Open        High         Low       Close  \\\n",
      "Date                                                                        \n",
      "2024-05-31 00:00:00-04:00  171.042245  172.236532  168.633762  171.679199   \n",
      "2024-06-03 00:00:00-04:00  171.719016  173.699553  170.345593  172.346024   \n",
      "2024-06-04 00:00:00-04:00  172.455506  173.022801  171.072120  172.963074   \n",
      "2024-06-05 00:00:00-04:00  174.366356  175.809453  173.102394  174.575363   \n",
      "2024-06-06 00:00:00-04:00  175.063016  176.307068  174.913736  175.889069   \n",
      "\n",
      "                             Volume  Dividends  Stock Splits  \n",
      "Date                                                          \n",
      "2024-05-31 00:00:00-04:00  37638900        0.0           0.0  \n",
      "2024-06-03 00:00:00-04:00  27459100        0.0           0.0  \n",
      "2024-06-04 00:00:00-04:00  26879600        0.0           0.0  \n",
      "2024-06-05 00:00:00-04:00  22068500        0.0           0.0  \n",
      "2024-06-06 00:00:00-04:00  23251000        0.0           0.0  \n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Define the ticker symbol\n",
    "tickerSymbol = 'GOOGL'\n",
    "\n",
    "# Get data on this ticker\n",
    "tickerData = yf.Ticker(tickerSymbol)\n",
    "\n",
    "# Get the stock price history\n",
    "tickerDf = tickerData.history(period='1y')\n",
    "\n",
    "# Print the last 5 rows of the DataFrame\n",
    "print(tickerDf.tail())\n",
    "print(tickerDf.head())\n",
    "# Save the DataFrame to a CSV file\n",
    "# tickerDf.to_csv('googl_stock_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickerDf.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This code first defines the ticker symbol for Google (GOOGL) and uses yfinance to get data on this ticker. It then uses the `history` method to get the stock price history for the last year from today and stores it in a Pandas DataFrame. Finally, it prints the last 5 rows of the DataFrame and saves the DataFrame to a CSV file named `googl_stock_data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Open      High       Low     Close     Volume  \\\n",
      "Date                                                                           \n",
      "2010-06-29 00:00:00-04:00  1.266667  1.666667  1.169333  1.592667  281494500   \n",
      "2010-06-30 00:00:00-04:00  1.719333  2.028000  1.553333  1.588667  257806500   \n",
      "2010-07-01 00:00:00-04:00  1.666667  1.728000  1.351333  1.464000  123282000   \n",
      "2010-07-02 00:00:00-04:00  1.533333  1.540000  1.247333  1.280000   77097000   \n",
      "2010-07-06 00:00:00-04:00  1.333333  1.333333  1.055333  1.074000  103003500   \n",
      "\n",
      "                           Dividends  Stock Splits  \n",
      "Date                                                \n",
      "2010-06-29 00:00:00-04:00        0.0           0.0  \n",
      "2010-06-30 00:00:00-04:00        0.0           0.0  \n",
      "2010-07-01 00:00:00-04:00        0.0           0.0  \n",
      "2010-07-02 00:00:00-04:00        0.0           0.0  \n",
      "2010-07-06 00:00:00-04:00        0.0           0.0  \n",
      "(2410, 7)\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# define ticker symbol\n",
    "tickerSymbol = 'TSLA'\n",
    "\n",
    "# get data on this ticker\n",
    "tickerData = yf.Ticker(tickerSymbol)\n",
    "# tickerData.info\n",
    "\n",
    "# get the historical prices for this ticker\n",
    "tickerDf = tickerData.history(period='1d', start='2010-1-1', end='2020-1-25')\n",
    "\n",
    "# last closing price\n",
    "tickerDf['Close'].iloc[-1]\n",
    "\n",
    "print(tickerDf.head())\n",
    "print(tickerDf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-06-03 00:00:00-04:00</th>\n",
       "      <td>469.148459</td>\n",
       "      <td>477.856710</td>\n",
       "      <td>466.537987</td>\n",
       "      <td>475.754364</td>\n",
       "      <td>11279400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-04 00:00:00-04:00</th>\n",
       "      <td>475.266199</td>\n",
       "      <td>477.149344</td>\n",
       "      <td>471.509913</td>\n",
       "      <td>475.256226</td>\n",
       "      <td>7088700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-05 00:00:00-04:00</th>\n",
       "      <td>482.689079</td>\n",
       "      <td>494.844715</td>\n",
       "      <td>482.151033</td>\n",
       "      <td>493.260498</td>\n",
       "      <td>15690500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-06 00:00:00-04:00</th>\n",
       "      <td>491.188107</td>\n",
       "      <td>500.992337</td>\n",
       "      <td>489.105708</td>\n",
       "      <td>491.965271</td>\n",
       "      <td>10667300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-07 00:00:00-04:00</th>\n",
       "      <td>494.107441</td>\n",
       "      <td>497.096537</td>\n",
       "      <td>488.388315</td>\n",
       "      <td>491.168152</td>\n",
       "      <td>9380700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Date                                                                        \n",
       "2024-06-03 00:00:00-04:00  469.148459  477.856710  466.537987  475.754364   \n",
       "2024-06-04 00:00:00-04:00  475.266199  477.149344  471.509913  475.256226   \n",
       "2024-06-05 00:00:00-04:00  482.689079  494.844715  482.151033  493.260498   \n",
       "2024-06-06 00:00:00-04:00  491.188107  500.992337  489.105708  491.965271   \n",
       "2024-06-07 00:00:00-04:00  494.107441  497.096537  488.388315  491.168152   \n",
       "\n",
       "                             Volume  Dividends  Stock Splits  \n",
       "Date                                                          \n",
       "2024-06-03 00:00:00-04:00  11279400        0.0           0.0  \n",
       "2024-06-04 00:00:00-04:00   7088700        0.0           0.0  \n",
       "2024-06-05 00:00:00-04:00  15690500        0.0           0.0  \n",
       "2024-06-06 00:00:00-04:00  10667300        0.0           0.0  \n",
       "2024-06-07 00:00:00-04:00   9380700        0.0           0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import datetime as dt\n",
    "from datetime import date, timedelta\n",
    "\n",
    "today = date.today()\n",
    "d1 = today.strftime(\"%Y-%m-%d\")\n",
    "d1\n",
    "d2 = (today - timedelta(days=365)).strftime(\"%Y-%m-%d\")\n",
    "d2\n",
    "start_date = d2\n",
    "end_date = d1\n",
    "\n",
    "# define ticker symbol\n",
    "tickerSymbol = 'META'\n",
    "\n",
    "# get data on this ticker\n",
    "tickerData = yf.Ticker(tickerSymbol)\n",
    "# tickerData.info\n",
    "\n",
    "# get the historical prices for this ticker\n",
    "tickerDf = tickerData.history(period='1d', start=start_date, end=end_date)\n",
    "tickerDf.head()\n",
    "\n",
    "# tickerDf.to_csv('META.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webscrapping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
